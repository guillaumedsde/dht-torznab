services:
  gluetun:
    image: docker.io/qmcgaw/gluetun@sha256:8eb8499c778e7b13ef5b23278e80390264cbeda8bfcc3d8b21fc07e0710f2fbb
    dns:
      - 1.1.1.1
      - 1.0.0.1
      - 127.0.0.11
    environment:
      LOG_LEVEL: ${GLUETUN_LOG_LEVEL:-info}
      VPN_SERVICE_PROVIDER: ${VPN_SERVICE_PROVIDER}
      VPN_TYPE: wireguard
      SERVER_COUNTRIES: ${VPN_SERVER_COUNTRIES}
      WIREGUARD_PRIVATE_KEY: ${WIREGUARD_PRIVATE_KEY}
      WIREGUARD_PRESHARED_KEY: ${WIREGUARD_PRESHARED_KEY}
      WIREGUARD_ADDRESSES: ${WIREGUARD_ADDRESSES}
      FIREWALL_VPN_INPUT_PORTS: ${FIREWALL_VPN_INPUT_PORTS}
      # Allow LAN access to other containers
      FIREWALL_OUTBOUND_SUBNETS: 172.16.0.0/12
      DNS_KEEP_NAMESERVER: "on"
      VERSION_INFORMATION: "off"
    cap_add:
      - NET_ADMIN
    devices:
      - /dev/net/tun:/dev/net/tun
    deploy:
      resources:
        limits:
          cpus: "2.0"
          memory: 500M
      restart_policy: &restart-policy
        condition: any

  magneticod:
    build:
      context: https://github.com/boramalper/magnetico.git#master
      dockerfile: Dockerfile.magneticod
    depends_on:
      beanstalkd:
        condition: service_started
      gluetun:
        condition: service_healthy
    command:
      - --database=beanstalkd://beanstalkd:11300/magneticod_tube
      - --verbose
      - --leech-max-n=500
      - --indexer-interval=1
      - --indexer-max-neighbors=10000
      - --indexer-addr=0.0.0.0:${MAGNETICOD_PORT:-0}
    network_mode: service:gluetun
    deploy:
      restart_policy: *restart-policy
      resources:
        limits:
          cpus: "4.0"
          memory: 150M

  beanstalkd:
    image: guillaumedsde/beanstalkd-distroless:1.13
    command:
      - -b
      - /data
      - -V
      - -f
      - "2400000"
      - -z
      - "10000000"
    volumes:
      - type: volume
        source: beanstalkd-binlog
        target: /data
    ports:
      - target: 11300
        published: 11300
        protocol: tcp
    deploy:
      restart_policy: *restart-policy
      resources:
        limits:
          cpus: "2.0"
          memory: 1G

  postgres:
    image: postgres:15-alpine
    ports:
      - target: 5432
        published: 5432
        protocol: tcp
    environment:
      POSTGRES_USER: torznab
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-torznab}
      POSTGRES_DB: torznab
    volumes:
      - type: volume
        source: pg-data
        target: /var/lib/postgresql/data
    command:
      - "postgres"
      - "-c"
      - "log_min_duration_statement=0"
      - "-c"
      - "max_connections=500"
    deploy:
      restart_policy: *restart-policy
      resources:
        limits:
          cpus: "4.0"
          memory: 4G
    healthcheck:
      test:
        - "CMD-SHELL"
        - "pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}"
      start_period: 5s
      interval: 10s
      timeout: 5s
      retries: 5

  listener: &common-dht-torznab
    build:
      context: .
      target: listener
    depends_on:
      migrations:
        condition: service_completed_successfully
    environment:
      DHT_TORZNAB__PGSQL_DSN: "postgresql+asyncpg://torznab:${POSTGRES_PASSWORD:-torznab}@postgres/"
      DHT_TORZNAB__BEANSTALKD_URL: "beanstalkd://beanstalkd:11300/magneticod_tube"
      DHT_TORZNAB__PEER_COUNT_UPDATER__DHT_UDP_SERVER_PORT: "${PEER_COUNT_UPDATER_PORT}"
    deploy:
      restart_policy: *restart-policy
      resources:
        limits:
          cpus: "1.5"
          memory: 150M

  migrations:
    <<: *common-dht-torznab
    build:
      context: .
      target: migrations
    depends_on:
      postgres:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 150M

  api:
    <<: *common-dht-torznab
    build:
      context: .
      target: api
    ports:
      - target: 8080
        published: 8080
        protocol: tcp
    deploy:
      restart_policy: *restart-policy
      resources:
        limits:
          cpus: "2.0"
          memory: 1G

  # FIXME DRY
  peer_count_updater:
    <<: *common-dht-torznab
    build:
      context: .
      target: peer_count_updater
    depends_on:
      migrations:
        condition: service_completed_successfully
      gluetun:
        condition: service_healthy
    network_mode: service:gluetun
    deploy:
      restart_policy: *restart-policy
      resources:
        limits:
          cpus: "4.0"
          memory: 500M

volumes:
  pg-data:
  beanstalkd-binlog:
